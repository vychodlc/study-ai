# 模块7: 低代码平台

## 课程概述

本模块深入讲解AI低代码平台的使用与部署，包括Coze和Dify两大主流平台的工作原理、实际应用和企业集成方法，帮助学员快速构建AI应用而无需大量编码。

---

## 第一章：Coze工作原理与应用实例

### 1.1 Coze平台介绍

#### 1.1.1 什么是Coze

**Coze（扣子）概述：**

Coze是字节跳动推出的AI Bot开发平台，支持零代码或低代码方式快速构建、发布和管理AI应用。

```
┌─────────────────────────────────────────────────────────────┐
│                    Coze平台架构                             │
├─────────────────────────────────────────────────────────────┤
│                                                             │
│  ┌─────────────────────────────────────────────────────┐    │
│  │                   用户界面层                        │    │
│  │  Bot配置 │ 工作流编辑 │ 插件管理 │ 知识库管理       │    │
│  └─────────────────────────────────────────────────────┘    │
│                           ↓                                 │
│  ┌─────────────────────────────────────────────────────┐    │
│  │                   核心能力层                        │    │
│  ├───────────┬───────────┬───────────┬─────────────────┤    │
│  │   插件    │   工作流   │  知识库   │    记忆        │    │
│  │ (Plugins) │ (Workflow) │   (RAG)   │  (Memory)      │    │
│  └───────────┴───────────┴───────────┴─────────────────┘    │
│                           ↓                                 │
│  ┌─────────────────────────────────────────────────────┐    │
│  │                   模型层                            │    │
│  │        GPT-4 │ 豆包 │ Claude │ 自定义模型           │    │
│  └─────────────────────────────────────────────────────┘    │
│                           ↓                                 │
│  ┌─────────────────────────────────────────────────────┐    │
│  │                   发布渠道                          │    │
│  │     Web │ API │ 微信 │ 飞书 │ Discord │ Telegram    │    │
│  └─────────────────────────────────────────────────────┘    │
│                                                             │
└─────────────────────────────────────────────────────────────┘
```

#### 1.1.2 插件使用

**内置插件类型：**

```
Coze插件分类：
├── 搜索类
│   ├── 必应搜索
│   ├── 谷歌搜索
│   └── 新闻搜索
├── 工具类
│   ├── 天气查询
│   ├── 翻译
│   ├── 计算器
│   └── 日期时间
├── 数据类
│   ├── 股票行情
│   ├── 汇率转换
│   └── 百科查询
├── 媒体类
│   ├── 图片生成
│   ├── 图片识别
│   └── 语音合成
└── 自定义插件
    └── 通过API接入自己的服务
```

**创建自定义插件：**

```json
// 插件定义示例
{
  "name": "order_query",
  "description": "查询用户订单状态",
  "parameters": {
    "type": "object",
    "properties": {
      "order_id": {
        "type": "string",
        "description": "订单编号"
      }
    },
    "required": ["order_id"]
  },
  "api": {
    "url": "https://api.yourcompany.com/orders/{order_id}",
    "method": "GET",
    "headers": {
      "Authorization": "Bearer {{api_key}}"
    }
  }
}
```

#### 1.1.3 工作流使用

**工作流节点类型：**

```
工作流节点：
├── 触发节点
│   └── 用户输入、定时触发、Webhook
├── LLM节点
│   └── 调用大模型进行推理
├── 代码节点
│   └── 执行自定义Python/JavaScript代码
├── 条件节点
│   └── 根据条件分支执行
├── 插件节点
│   └── 调用内置或自定义插件
├── 知识库节点
│   └── 检索知识库内容
├── 变量节点
│   └── 设置和读取变量
└── 结束节点
    └── 返回结果
```

**工作流示例：智能客服**

```
┌──────────────┐
│   用户输入   │
└──────┬───────┘
       ↓
┌──────────────┐
│  意图识别    │ (LLM节点)
│  分类问题类型 │
└──────┬───────┘
       ↓
┌──────────────┐     ┌──────────────┐     ┌──────────────┐
│  产品咨询？  │────→│   知识库     │────→│   生成回答   │
└──────────────┘     │   检索       │     └──────────────┘
       │             └──────────────┘
       ↓
┌──────────────┐     ┌──────────────┐     ┌──────────────┐
│  订单查询？  │────→│  订单插件    │────→│   格式化结果  │
└──────────────┘     │   调用       │     └──────────────┘
       │             └──────────────┘
       ↓
┌──────────────┐
│  其他问题    │────→ 转人工客服
└──────────────┘
```

### 1.2 Coze实战案例

#### 1.2.1 CASE：AI新闻Agent

**配置步骤：**

```
1. 创建Bot
   - 名称：每日新闻助手
   - 描述：获取最新新闻并提供摘要分析

2. 配置人设提示词：
"""
你是一个专业的新闻分析助手。你的职责是：
1. 根据用户需求搜索最新新闻
2. 筛选最相关的新闻内容
3. 提供简洁的新闻摘要
4. 分析新闻的影响和意义

回答时请：
- 标注新闻来源和时间
- 保持客观中立
- 突出关键信息
"""

3. 添加插件
   - 必应新闻搜索
   - 网页内容获取

4. 创建工作流
   - 接收用户新闻主题
   - 调用搜索插件
   - LLM分析和总结
   - 格式化输出

5. 测试发布
```

#### 1.2.2 CASE：基于意图识别的weather_news工作流

```python
# 工作流逻辑（伪代码表示）

def weather_news_workflow(user_input):
    # 1. 意图识别
    intent = llm_classify(
        prompt=f"""
        判断以下用户输入的意图类型：
        - weather: 查询天气
        - news: 查询新闻
        - other: 其他

        用户输入：{user_input}
        意图类型：
        """,
        options=["weather", "news", "other"]
    )

    # 2. 根据意图路由
    if intent == "weather":
        # 提取城市
        city = llm_extract(
            prompt=f"从'{user_input}'中提取城市名称："
        )
        # 调用天气插件
        weather_data = weather_plugin.query(city=city)
        # 生成回答
        response = llm_generate(
            prompt=f"根据以下天气数据生成友好的回答：{weather_data}"
        )

    elif intent == "news":
        # 提取关键词
        keywords = llm_extract(
            prompt=f"从'{user_input}'中提取新闻关键词："
        )
        # 调用新闻搜索
        news_data = news_plugin.search(query=keywords)
        # 生成摘要
        response = llm_generate(
            prompt=f"总结以下新闻内容：{news_data}"
        )

    else:
        response = "抱歉，我目前只能提供天气查询和新闻搜索服务。"

    return response
```

#### 1.2.3 CASE：搭建古诗词Agent

**Bot配置：**

```
1. 人设提示词：
"""
你是一位博学的古诗词专家，精通中国古典诗词。你的能力包括：

1. 诗词知识问答
   - 解释诗词含义
   - 介绍作者生平
   - 分析写作背景

2. 诗词推荐
   - 根据心情推荐诗词
   - 根据场景推荐诗词
   - 根据主题推荐诗词

3. 诗词创作辅助
   - 帮助理解平仄韵律
   - 提供写作建议

回答风格：
- 引经据典，有理有据
- 语言优美，富有诗意
- 适当引用原文
"""

2. 知识库配置：
   - 上传《唐诗三百首》
   - 上传《宋词三百首》
   - 上传诗人传记资料

3. 工作流设计：
   - 用户输入解析
   - 知识库检索
   - LLM生成回答
   - 推荐相关诗词
```

### 1.3 Coze本地化部署

#### 1.3.1 Coze-Studio本地部署

```bash
# 1. 环境准备
# 需要Docker和Docker Compose

# 2. 克隆代码
git clone https://github.com/coze-dev/coze-studio.git
cd coze-studio

# 3. 配置环境变量
cp .env.example .env
# 编辑.env，配置模型API等

# 4. 启动服务
docker-compose up -d

# 5. 访问
# 打开 http://localhost:3000

# 6. 接入本地模型（如Ollama）
# 在.env中配置：
# OLLAMA_BASE_URL=http://localhost:11434
```

#### 1.3.2 接入本地大模型

```python
# 配置本地模型作为Coze的后端

# 1. 启动Ollama
# ollama serve

# 2. 在Coze中配置模型端点
model_config = {
    "name": "local-qwen",
    "provider": "ollama",
    "base_url": "http://localhost:11434",
    "model": "qwen:7b",
    "api_type": "openai_compatible"
}

# 3. 或使用vLLM提供OpenAI兼容API
# python -m vllm.entrypoints.openai.api_server \
#     --model Qwen/Qwen2-7B-Instruct \
#     --port 8000

# 在Coze中配置：
model_config = {
    "name": "local-vllm",
    "provider": "openai_compatible",
    "base_url": "http://localhost:8000/v1",
    "model": "Qwen/Qwen2-7B-Instruct"
}
```

---

## 第二章：Dify本地化部署和应用

### 2.1 Dify平台介绍

#### 2.1.1 Dify开发平台

**Dify核心特点：**

```
┌─────────────────────────────────────────────────────────────┐
│                    Dify平台特点                             │
├─────────────────────────────────────────────────────────────┤
│                                                             │
│  1. 开源可控                                                │
│     ├── 完全开源，可自托管                                   │
│     ├── 数据完全自主可控                                    │
│     └── 支持私有化部署                                      │
│                                                             │
│  2. 应用类型                                                │
│     ├── 聊天助手（Chatbot）                                 │
│     ├── 文本生成（Completion）                              │
│     ├── Agent（智能体）                                     │
│     └── 工作流（Workflow）                                  │
│                                                             │
│  3. 核心能力                                                │
│     ├── Prompt IDE：可视化提示词编辑                        │
│     ├── RAG Pipeline：知识库检索                            │
│     ├── Agent：工具调用和自主决策                           │
│     ├── Workflow：可视化流程编排                            │
│     └── LLMOps：模型管理和监控                              │
│                                                             │
│  4. 模型支持                                                │
│     ├── OpenAI / Azure OpenAI                               │
│     ├── Claude / Gemini                                     │
│     ├── 通义千问 / 智谱 / 百川                              │
│     └── 本地模型（Ollama / vLLM）                           │
│                                                             │
└─────────────────────────────────────────────────────────────┘
```

#### 2.1.2 Docker Compose部署

```bash
# 1. 克隆代码
git clone https://github.com/langgenius/dify.git
cd dify/docker

# 2. 复制环境配置
cp .env.example .env

# 3. 编辑.env文件
# 主要配置项：
# - SECRET_KEY: 应用密钥
# - CONSOLE_URL: 控制台URL
# - API_URL: API服务URL
# - 数据库配置
# - Redis配置
# - 存储配置

# 4. 启动服务
docker-compose up -d

# 5. 查看服务状态
docker-compose ps

# 服务组成：
# - api: 后端API服务
# - worker: 异步任务处理
# - web: 前端Web应用
# - db: PostgreSQL数据库
# - redis: Redis缓存
# - weaviate: 向量数据库
# - nginx: 反向代理

# 6. 访问Dify
# 打开 http://localhost:3000
# 首次访问需要设置管理员账号

# 7. 停止服务
docker-compose down

# 8. 更新版本
git pull
docker-compose pull
docker-compose up -d
```

#### 2.1.3 配置模型提供商

```python
# Dify支持的模型配置方式

# 1. OpenAI
{
    "provider": "openai",
    "model": "gpt-4",
    "api_key": "sk-xxx",
    "base_url": "https://api.openai.com/v1"  # 可自定义
}

# 2. 本地Ollama
{
    "provider": "ollama",
    "model": "qwen:7b",
    "base_url": "http://localhost:11434"
}

# 3. 本地vLLM（OpenAI兼容）
{
    "provider": "openai_api_compatible",
    "model": "Qwen/Qwen2-7B-Instruct",
    "api_key": "none",
    "base_url": "http://localhost:8000/v1"
}

# 4. 通义千问
{
    "provider": "tongyi",
    "model": "qwen-max",
    "api_key": "your-dashscope-api-key"
}
```

### 2.2 Dify应用实战

#### 2.2.1 CASE：LLM联网搜索

```yaml
# 工作流配置

name: 联网搜索助手
description: 支持实时搜索的问答助手

workflow:
  # 开始节点
  - id: start
    type: start
    outputs:
      - query

  # 搜索节点
  - id: web_search
    type: tool
    tool_name: google_search  # 或 bing_search
    inputs:
      query: "{{start.query}}"
    outputs:
      - search_results

  # LLM处理节点
  - id: llm_process
    type: llm
    model: gpt-4
    prompt: |
      请根据以下搜索结果回答用户的问题。

      用户问题：{{start.query}}

      搜索结果：
      {{web_search.search_results}}

      请提供准确、有用的回答，并标注信息来源。
    outputs:
      - answer

  # 结束节点
  - id: end
    type: end
    inputs:
      result: "{{llm_process.answer}}"
```

#### 2.2.2 CASE：智能客服ChatFlow

```yaml
# ChatFlow配置

name: 智能客服
type: chatflow

# 开场白
opening_statement: |
  您好！我是智能客服助手，可以为您提供以下服务：
  1. 产品咨询
  2. 订单查询
  3. 售后服务
  请问有什么可以帮您？

# 建议问题
suggested_questions:
  - 你们有什么产品？
  - 怎么查询我的订单？
  - 如何申请退款？

# 知识库配置
knowledge_base:
  datasets:
    - id: product_docs
      name: 产品文档库
    - id: faq_docs
      name: 常见问题库
  retrieval:
    mode: semantic  # semantic / keyword / hybrid
    top_k: 3
    score_threshold: 0.5

# 工作流节点
nodes:
  # 意图分类
  - id: intent_classifier
    type: llm
    model: gpt-3.5-turbo
    prompt: |
      分析用户意图，分类为以下类型之一：
      - product_inquiry: 产品咨询
      - order_query: 订单查询
      - after_sales: 售后服务
      - other: 其他

      用户输入：{{user_input}}
      意图类型：

  # 条件分支
  - id: router
    type: condition
    conditions:
      - when: "{{intent_classifier.output}} == 'order_query'"
        goto: order_handler
      - when: "{{intent_classifier.output}} == 'after_sales'"
        goto: after_sales_handler
      - default:
        goto: knowledge_qa

  # 知识库问答
  - id: knowledge_qa
    type: knowledge_retrieval
    dataset_ids: [product_docs, faq_docs]
    query: "{{user_input}}"

  # 订单查询
  - id: order_handler
    type: tool
    tool_name: order_api
    inputs:
      action: query
      user_id: "{{context.user_id}}"

  # 生成回答
  - id: answer_generator
    type: llm
    model: gpt-4
    prompt: |
      根据以下信息生成回答：
      {{previous_node.output}}

      要求：
      1. 语气友好专业
      2. 信息准确完整
      3. 如无法解决，引导转人工
```

#### 2.2.3 CASE：智能文档分析助手

```python
# 结合MinerU的文档分析助手

"""
架构设计：
1. 使用MinerU解析PDF/Word等文档
2. 解析结果存入Dify知识库
3. 使用Dify构建问答应用
"""

# 1. MinerU文档解析
from magic_pdf.pipe.UNIPipe import UNIPipe
from magic_pdf.rw.DiskReaderWriter import DiskReaderWriter

def parse_document(pdf_path):
    """使用MinerU解析PDF"""
    # 读取PDF
    reader = DiskReaderWriter(pdf_path)
    pdf_bytes = reader.read()

    # 解析
    pipe = UNIPipe(pdf_bytes, [], image_writer=None)
    pipe.pipe_classify()
    pipe.pipe_analyze()
    pipe.pipe_parse()

    # 获取Markdown结果
    md_content = pipe.pipe_mk_markdown()
    return md_content

# 2. 上传到Dify知识库
import requests

def upload_to_dify(content, dataset_id, api_key):
    """上传文档到Dify知识库"""
    url = f"http://localhost:3000/v1/datasets/{dataset_id}/document/create_by_text"

    headers = {
        "Authorization": f"Bearer {api_key}",
        "Content-Type": "application/json"
    }

    data = {
        "name": "parsed_document",
        "text": content,
        "indexing_technique": "high_quality",
        "process_rule": {
            "mode": "custom",
            "rules": {
                "pre_processing_rules": [
                    {"id": "remove_extra_spaces", "enabled": True}
                ],
                "segmentation": {
                    "separator": "\n\n",
                    "max_tokens": 500
                }
            }
        }
    }

    response = requests.post(url, headers=headers, json=data)
    return response.json()

# 3. 完整流程
def process_and_index(pdf_path, dataset_id, api_key):
    # 解析文档
    md_content = parse_document(pdf_path)

    # 上传到Dify
    result = upload_to_dify(md_content, dataset_id, api_key)

    print(f"文档已索引: {result}")
    return result
```

### 2.3 API调用

#### 2.3.1 Coze API使用

```python
# Coze API调用示例
import requests

class CozeClient:
    def __init__(self, api_key, bot_id):
        self.api_key = api_key
        self.bot_id = bot_id
        self.base_url = "https://api.coze.cn/v1"

    def chat(self, message, conversation_id=None):
        """发送对话请求"""
        url = f"{self.base_url}/chat"

        headers = {
            "Authorization": f"Bearer {self.api_key}",
            "Content-Type": "application/json"
        }

        data = {
            "bot_id": self.bot_id,
            "user": "user_001",
            "query": message,
            "stream": False
        }

        if conversation_id:
            data["conversation_id"] = conversation_id

        response = requests.post(url, headers=headers, json=data)
        return response.json()

    def chat_stream(self, message, conversation_id=None):
        """流式对话"""
        url = f"{self.base_url}/chat"

        headers = {
            "Authorization": f"Bearer {self.api_key}",
            "Content-Type": "application/json"
        }

        data = {
            "bot_id": self.bot_id,
            "user": "user_001",
            "query": message,
            "stream": True
        }

        if conversation_id:
            data["conversation_id"] = conversation_id

        response = requests.post(url, headers=headers, json=data, stream=True)

        for line in response.iter_lines():
            if line:
                yield line.decode('utf-8')


# 使用cozepy库（官方SDK）
from cozepy import Coze, ChatEventType

coze = Coze(auth_token="your_token")

# 非流式调用
chat = coze.chat.create(
    bot_id="your_bot_id",
    user_id="user_001",
    messages=[{"role": "user", "content": "你好"}]
)
print(chat.messages[-1].content)

# 流式调用
for event in coze.chat.stream(
    bot_id="your_bot_id",
    user_id="user_001",
    messages=[{"role": "user", "content": "你好"}]
):
    if event.event == ChatEventType.CONVERSATION_MESSAGE_DELTA:
        print(event.message.content, end="")
```

#### 2.3.2 Dify API使用

```python
# Dify API调用示例
import requests

class DifyClient:
    def __init__(self, api_key, base_url="http://localhost:3000"):
        self.api_key = api_key
        self.base_url = base_url

    def chat(self, query, conversation_id=None, user="default"):
        """聊天接口"""
        url = f"{self.base_url}/v1/chat-messages"

        headers = {
            "Authorization": f"Bearer {self.api_key}",
            "Content-Type": "application/json"
        }

        data = {
            "inputs": {},
            "query": query,
            "response_mode": "blocking",  # blocking / streaming
            "user": user
        }

        if conversation_id:
            data["conversation_id"] = conversation_id

        response = requests.post(url, headers=headers, json=data)
        return response.json()

    def chat_stream(self, query, conversation_id=None, user="default"):
        """流式聊天"""
        url = f"{self.base_url}/v1/chat-messages"

        headers = {
            "Authorization": f"Bearer {self.api_key}",
            "Content-Type": "application/json"
        }

        data = {
            "inputs": {},
            "query": query,
            "response_mode": "streaming",
            "user": user
        }

        if conversation_id:
            data["conversation_id"] = conversation_id

        response = requests.post(url, headers=headers, json=data, stream=True)

        for line in response.iter_lines():
            if line:
                line = line.decode('utf-8')
                if line.startswith('data: '):
                    yield line[6:]

    def upload_file(self, file_path):
        """上传文件"""
        url = f"{self.base_url}/v1/files/upload"

        headers = {
            "Authorization": f"Bearer {self.api_key}"
        }

        with open(file_path, 'rb') as f:
            files = {"file": f}
            response = requests.post(url, headers=headers, files=files)

        return response.json()


# 使用示例
client = DifyClient(api_key="app-xxx")

# 对话
result = client.chat("什么是人工智能？")
print(result["answer"])

# 带上下文的对话
result1 = client.chat("介绍一下Python")
conversation_id = result1["conversation_id"]

result2 = client.chat("它有什么优点？", conversation_id=conversation_id)
print(result2["answer"])
```

---

## 第三章：Agent调试、运维与系统集成

### 3.1 低代码Agent的调试与发布

#### 3.1.1 工作流调试技巧

```
调试方法：

1. 单步执行
   - 在Dify/Coze中启用调试模式
   - 逐节点执行，查看中间结果
   - 检查变量值是否符合预期

2. 日志分析
   - 查看每个节点的输入输出
   - 检查LLM的prompt和response
   - 分析错误堆栈

3. 常见问题排查
   ├── 意图识别不准确
   │   └── 优化分类prompt，增加示例
   ├── 知识库检索不相关
   │   └── 调整检索参数，优化文档切分
   ├── 工具调用失败
   │   └── 检查API连接，验证参数格式
   └── 响应格式错误
       └── 增加输出格式约束

4. 测试用例
   - 准备覆盖各场景的测试集
   - 定期回归测试
   - 记录失败用例持续改进
```

#### 3.1.2 版本管理与发布

```python
# Dify应用版本管理

# 1. 导出应用配置
def export_app(app_id, api_key):
    """导出应用配置为DSL"""
    url = f"http://localhost:3000/v1/apps/{app_id}/export"
    headers = {"Authorization": f"Bearer {api_key}"}

    response = requests.get(url, headers=headers)
    return response.json()

# 2. 导入应用配置
def import_app(dsl_config, api_key):
    """从DSL导入应用"""
    url = "http://localhost:3000/v1/apps/import"
    headers = {
        "Authorization": f"Bearer {api_key}",
        "Content-Type": "application/json"
    }

    response = requests.post(url, headers=headers, json=dsl_config)
    return response.json()

# 3. 版本管理实践
"""
目录结构：
app_versions/
├── v1.0.0/
│   ├── app_config.json
│   ├── prompts/
│   └── README.md
├── v1.1.0/
│   ├── app_config.json
│   ├── prompts/
│   └── CHANGELOG.md
└── current -> v1.1.0  # 软链接指向当前版本

发布流程：
1. 开发环境测试通过
2. 导出配置，打包版本
3. 在预发布环境验证
4. 发布到生产环境
5. 监控关键指标
6. 如有问题，快速回滚
"""
```

### 3.2 低代码平台与企业系统集成

#### 3.2.1 集成策略

```
┌─────────────────────────────────────────────────────────────┐
│                   企业系统集成策略                           │
├─────────────────────────────────────────────────────────────┤
│                                                             │
│  方式1：API封装（推荐）                                      │
│  ┌──────────────┐                                          │
│  │  企业系统     │                                          │
│  │  (CRM/ERP)   │                                          │
│  └──────┬───────┘                                          │
│         ↓                                                   │
│  ┌──────────────┐                                          │
│  │  API网关/    │                                          │
│  │  适配层      │                                          │
│  └──────┬───────┘                                          │
│         ↓                                                   │
│  ┌──────────────┐                                          │
│  │  Coze/Dify   │                                          │
│  │  (插件/工具)  │                                          │
│  └──────────────┘                                          │
│                                                             │
│  方式2：数据库直连（需谨慎）                                  │
│  - 只读访问                                                 │
│  - 严格权限控制                                             │
│  - 查询优化避免影响业务                                      │
│                                                             │
│  方式3：消息队列（异步场景）                                  │
│  - 适合非实时场景                                           │
│  - 解耦系统依赖                                             │
│                                                             │
└─────────────────────────────────────────────────────────────┘
```

#### 3.2.2 CASE：Agent查询内部订单系统

```python
# 1. 创建订单查询API适配器

from flask import Flask, request, jsonify
import requests

app = Flask(__name__)

# 内部订单系统配置
ORDER_SYSTEM_URL = "http://internal-order-system/api"
ORDER_SYSTEM_TOKEN = "internal-token"

@app.route('/api/orders/<order_id>', methods=['GET'])
def query_order(order_id):
    """订单查询API - 供Coze/Dify调用"""
    try:
        # 调用内部系统
        response = requests.get(
            f"{ORDER_SYSTEM_URL}/orders/{order_id}",
            headers={"Authorization": f"Bearer {ORDER_SYSTEM_TOKEN}"}
        )

        if response.status_code == 200:
            order = response.json()
            # 转换为适合AI理解的格式
            return jsonify({
                "success": True,
                "order": {
                    "order_id": order["id"],
                    "status": translate_status(order["status"]),
                    "create_time": order["created_at"],
                    "total_amount": f"¥{order['amount']}",
                    "items": [
                        {"name": item["product_name"], "quantity": item["qty"]}
                        for item in order["items"]
                    ],
                    "shipping": {
                        "status": order["shipping_status"],
                        "tracking_no": order.get("tracking_no", "暂无")
                    }
                }
            })
        else:
            return jsonify({
                "success": False,
                "error": "订单不存在"
            })

    except Exception as e:
        return jsonify({
            "success": False,
            "error": str(e)
        })

def translate_status(status_code):
    """状态码转中文"""
    status_map = {
        "pending": "待付款",
        "paid": "已付款",
        "shipped": "已发货",
        "delivered": "已送达",
        "completed": "已完成",
        "cancelled": "已取消"
    }
    return status_map.get(status_code, status_code)

# 2. 在Dify中配置为工具
"""
工具配置：
{
  "name": "order_query",
  "description": "查询用户订单信息，返回订单状态、商品明细、物流信息等",
  "parameters": {
    "type": "object",
    "properties": {
      "order_id": {
        "type": "string",
        "description": "订单编号，如：ORD2024001"
      }
    },
    "required": ["order_id"]
  },
  "api": {
    "url": "http://api-gateway/api/orders/{order_id}",
    "method": "GET",
    "headers": {
      "X-API-Key": "{{api_key}}"
    }
  }
}
"""

# 3. Agent提示词配置
"""
你是一个订单客服助手。当用户询问订单相关问题时：

1. 首先确认用户提供了订单号
2. 如果没有提供，请用户提供订单号
3. 调用order_query工具查询订单
4. 根据查询结果，友好地告知用户：
   - 订单当前状态
   - 商品信息
   - 物流信息（如有）
5. 如果查询失败，安抚用户并建议联系人工客服

注意：
- 保护用户隐私，不要透露敏感信息
- 对于退款等敏感操作，引导用户到官方渠道
"""
```

---

## 本模块总结

### 核心能力清单

1. **Coze使用**：掌握插件、工作流、知识库配置
2. **Dify部署**：能进行Docker本地部署和配置
3. **工作流设计**：能设计复杂的多步骤工作流
4. **API调用**：掌握Coze和Dify的API使用
5. **系统集成**：能将AI应用与企业系统集成

### Coze vs Dify对比

| 维度 | Coze | Dify |
|------|------|------|
| 部署方式 | SaaS为主 | 开源自托管 |
| 数据控制 | 平台托管 | 完全自主 |
| 易用性 | 更简单 | 稍复杂 |
| 定制能力 | 中等 | 强 |
| 企业适用 | 快速验证 | 生产部署 |

### 实践建议

1. 快速原型用Coze，生产部署用Dify
2. 重视工作流的测试和调试
3. API集成注意安全和权限控制
4. 建立版本管理和回滚机制
