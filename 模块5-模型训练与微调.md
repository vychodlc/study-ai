# 模块5: 模型训练与微调

## 课程概述

本模块深入讲解大语言模型的微调技术，从LoRA等高效微调方法的数学原理出发，到数据工程、模型蒸馏、多模态模型训练，最后通过AI质检项目实战，帮助学员掌握完整的模型训练与微调能力。

---

## 第一章：LLM微调原理

### 1.1 LLM的微调原理

#### 1.1.1 为什么需要微调

**微调的核心价值：**

```
┌─────────────────────────────────────────────────────────────┐
│                   为什么需要微调？                           │
├─────────────────────────────────────────────────────────────┤
│                                                             │
│  预训练模型的局限：                                          │
│  ├── 通用能力强，但领域专业度不足                            │
│  ├── 输出风格固定，难以定制                                  │
│  ├── 可能不了解企业特定知识                                  │
│  └── 指令遵循能力可能不够精确                                │
│                                                             │
│  微调带来的提升：                                            │
│  ├── 领域适应：学习专业术语和知识                            │
│  ├── 风格定制：匹配特定的输出格式和语气                       │
│  ├── 任务优化：提升特定任务的性能                            │
│  └── 行为对齐：更好地遵循指令和约束                          │
│                                                             │
│  微调 vs RAG：                                               │
│  ├── 微调：改变模型的"能力"和"风格"                         │
│  └── RAG：提供模型的"知识"和"信息"                          │
│  通常组合使用效果最佳                                        │
│                                                             │
└─────────────────────────────────────────────────────────────┘
```

#### 1.1.2 高效微调方法概览

**主流PEFT方法：**

| 方法 | 核心思想 | 参数量 | 适用场景 |
|------|----------|--------|----------|
| LoRA | 低秩矩阵分解 | 0.1%-1% | 通用，最常用 |
| QLoRA | 量化+LoRA | 更低 | 显存受限 |
| Prefix Tuning | 学习前缀向量 | ~0.1% | 生成任务 |
| Prompt Tuning | 软提示学习 | 极少 | 简单任务 |
| Adapter | 插入适配层 | ~1% | 多任务 |
| IA3 | 缩放激活值 | 极少 | 轻量级 |

#### 1.1.3 LoRA的数学原理

**LoRA核心假设：**

LoRA (Low-Rank Adaptation) 基于一个关键假设：模型微调时的权重更新矩阵是低秩的，可以用两个小矩阵的乘积来近似。

```
┌─────────────────────────────────────────────────────────────┐
│                    LoRA数学原理                             │
├─────────────────────────────────────────────────────────────┤
│                                                             │
│  原始权重更新：                                              │
│  W' = W + ΔW                                                │
│  其中 W ∈ R^(d×k)，ΔW ∈ R^(d×k)                            │
│                                                             │
│  LoRA的低秩分解：                                            │
│  ΔW = B × A                                                 │
│  其中 B ∈ R^(d×r)，A ∈ R^(r×k)，r << min(d,k)              │
│                                                             │
│  参数量对比：                                                │
│  原始：d × k                                                │
│  LoRA：d × r + r × k = r × (d + k)                         │
│                                                             │
│  例如：d=4096, k=4096, r=8                                  │
│  原始：4096 × 4096 = 16,777,216 参数                        │
│  LoRA：8 × (4096 + 4096) = 65,536 参数                      │
│  压缩比：约 256 倍                                           │
│                                                             │
│  前向传播：                                                  │
│  h = Wx + (α/r) × BAx                                       │
│  α 是缩放因子，通常设为 r 的值                               │
│                                                             │
└─────────────────────────────────────────────────────────────┘
```

**LoRA可视化：**

```
原始Transformer层：
                    ┌─────────┐
        输入 x ────→│   W     │────→ 输出
                    └─────────┘

LoRA增强后：
                    ┌─────────┐
              ┌────→│   W     │────┐
              │     └─────────┘    │
        输入 x│                     │+ ──→ 输出
              │     ┌───┐  ┌───┐   │
              └────→│ A │→ │ B │───┘
                    └───┘  └───┘
                    (r×k)  (d×r)

        冻结原始W，只训练A和B
```

#### 1.1.4 矩阵分解与SVD

**SVD（奇异值分解）原理：**

```python
import numpy as np

# SVD分解示例
def explain_svd():
    # 创建一个矩阵
    W = np.random.randn(100, 100)

    # SVD分解：W = U × Σ × V^T
    U, S, Vt = np.linalg.svd(W)

    print(f"U shape: {U.shape}")   # (100, 100)
    print(f"S shape: {S.shape}")   # (100,) 奇异值
    print(f"Vt shape: {Vt.shape}") # (100, 100)

    # 观察奇异值的衰减
    print(f"前10个奇异值: {S[:10]}")
    print(f"后10个奇异值: {S[-10:]}")

    # 低秩近似：只保留前r个奇异值
    r = 10
    W_approx = U[:, :r] @ np.diag(S[:r]) @ Vt[:r, :]

    # 计算近似误差
    error = np.linalg.norm(W - W_approx) / np.linalg.norm(W)
    print(f"保留{r}个奇异值的相对误差: {error:.4f}")

    return W_approx

# LoRA的初始化策略
def lora_init(d, k, r):
    """LoRA参数初始化"""
    # A使用高斯初始化
    A = np.random.randn(r, k) * 0.01

    # B初始化为0，确保训练开始时ΔW=0
    B = np.zeros((d, r))

    return A, B
```

**为什么低秩假设成立：**

```
研究发现，预训练模型微调时：
1. 权重变化ΔW的有效秩很低
2. 大部分信息集中在少数几个方向上
3. 这意味着可以用低维子空间捕获主要变化

这解释了为什么LoRA在r=8或r=16时就能取得好效果
```

---

### 1.2 LLM微调的数据处理与显存评估

#### 1.2.1 微调数据准备

**SFT数据格式：**

```python
# Alpaca格式
alpaca_format = {
    "instruction": "将以下英文翻译成中文",
    "input": "Hello, how are you?",
    "output": "你好，你怎么样？"
}

# ShareGPT格式（多轮对话）
sharegpt_format = {
    "conversations": [
        {"from": "human", "value": "什么是机器学习？"},
        {"from": "gpt", "value": "机器学习是人工智能的一个分支..."},
        {"from": "human", "value": "它和深度学习有什么区别？"},
        {"from": "gpt", "value": "深度学习是机器学习的子集..."}
    ]
}

# 转换为模型输入格式
def format_alpaca_prompt(sample, tokenizer):
    if sample["input"]:
        prompt = f"""### 指令:
{sample["instruction"]}

### 输入:
{sample["input"]}

### 回答:
{sample["output"]}"""
    else:
        prompt = f"""### 指令:
{sample["instruction"]}

### 回答:
{sample["output"]}"""

    return tokenizer(prompt, truncation=True, max_length=2048)
```

#### 1.2.2 数据质量与数量要求

**数据质量检查清单：**

```
┌─────────────────────────────────────────────────────────────┐
│                   微调数据质量标准                           │
├─────────────────────────────────────────────────────────────┤
│                                                             │
│  格式规范：                                                  │
│  ├── 指令清晰明确                                           │
│  ├── 输出符合预期格式                                        │
│  ├── 无格式错误（JSON、特殊字符等）                          │
│  └── 长度适中（不过长也不过短）                              │
│                                                             │
│  内容质量：                                                  │
│  ├── 指令和输出匹配                                         │
│  ├── 输出准确、专业                                         │
│  ├── 无事实错误                                             │
│  ├── 无有害内容                                             │
│  └── 语言流畅自然                                           │
│                                                             │
│  数据多样性：                                                │
│  ├── 覆盖目标场景的各种情况                                  │
│  ├── 指令表述多样                                           │
│  ├── 难度分布合理                                           │
│  └── 避免过度重复                                           │
│                                                             │
│  数量参考：                                                  │
│  ├── 简单任务：1000-5000条                                  │
│  ├── 中等任务：5000-20000条                                 │
│  ├── 复杂任务：20000-100000条                               │
│  └── 质量 > 数量                                            │
│                                                             │
└─────────────────────────────────────────────────────────────┘
```

#### 1.2.3 硬件需求与显存计算

**显存估算方法：**

```python
def estimate_memory(model_size_b, precision='fp16', batch_size=1,
                    seq_length=2048, use_lora=False, lora_r=8):
    """
    估算训练所需显存

    Args:
        model_size_b: 模型参数量（十亿）
        precision: 精度 ('fp32', 'fp16', 'int8', 'int4')
        batch_size: 批次大小
        seq_length: 序列长度
        use_lora: 是否使用LoRA
        lora_r: LoRA的秩
    """
    # 每个参数的字节数
    bytes_per_param = {
        'fp32': 4,
        'fp16': 2,
        'bf16': 2,
        'int8': 1,
        'int4': 0.5
    }

    param_bytes = bytes_per_param[precision]
    total_params = model_size_b * 1e9

    # 模型权重
    model_memory = total_params * param_bytes / 1e9  # GB

    # 优化器状态（Adam需要2倍参数量）
    if use_lora:
        # LoRA只训练约0.1%-1%的参数
        trainable_params = total_params * 0.005  # 假设0.5%
        optimizer_memory = trainable_params * 8 / 1e9  # Adam: 8字节/参数
    else:
        optimizer_memory = total_params * 8 / 1e9

    # 梯度
    gradient_memory = trainable_params * param_bytes / 1e9 if use_lora else model_memory

    # 激活值（粗略估计）
    # 激活值大小 ≈ batch_size × seq_length × hidden_dim × num_layers × 4
    hidden_dim = int((total_params / 12 / 32) ** 0.5)  # 粗略估计
    activation_memory = batch_size * seq_length * hidden_dim * 32 * 4 / 1e9

    total = model_memory + optimizer_memory + gradient_memory + activation_memory

    print(f"模型权重: {model_memory:.2f} GB")
    print(f"优化器状态: {optimizer_memory:.2f} GB")
    print(f"梯度: {gradient_memory:.2f} GB")
    print(f"激活值(估计): {activation_memory:.2f} GB")
    print(f"总计: {total:.2f} GB")

    return total


# 示例
print("=== 7B模型全量微调 ===")
estimate_memory(7, 'fp16', batch_size=1, use_lora=False)

print("\n=== 7B模型LoRA微调 ===")
estimate_memory(7, 'fp16', batch_size=4, use_lora=True)

print("\n=== 7B模型QLoRA微调 ===")
estimate_memory(7, 'int4', batch_size=4, use_lora=True)
```

**不同规模模型的硬件需求：**

| 模型规模 | 全量微调 | LoRA (fp16) | QLoRA (int4) |
|---------|---------|-------------|--------------|
| 7B | 80GB+ | 24GB | 8GB |
| 13B | 160GB+ | 40GB | 12GB |
| 30B | 400GB+ | 80GB | 24GB |
| 70B | 1TB+ | 200GB | 48GB |

---

## 第二章：高质量微调数据工程与评估

### 2.1 微调数据的收集、清洗、标准

#### 2.1.1 数据收集策略

```python
class DataCollectionPipeline:
    """数据收集管线"""

    def __init__(self):
        self.sources = []

    def collect_from_existing_data(self, data_path):
        """从现有业务数据收集"""
        # 日志、客服记录、文档等
        pass

    def generate_synthetic_data(self, llm, seed_examples, num_samples):
        """使用LLM生成合成数据"""
        synthetic_data = []

        for _ in range(num_samples):
            # 选择一个种子示例
            seed = random.choice(seed_examples)

            # 让LLM生成类似的新样本
            prompt = f"""请模仿以下示例的风格，生成一个新的指令-回答对：

示例：
指令：{seed['instruction']}
回答：{seed['output']}

请生成一个不同的但类似的指令-回答对："""

            response = llm.generate(prompt)
            # 解析并添加
            synthetic_data.append(parse_response(response))

        return synthetic_data

    def augment_data(self, data):
        """数据增强"""
        augmented = []
        for sample in data:
            # 原始样本
            augmented.append(sample)

            # 指令改写
            rewritten = self.rewrite_instruction(sample)
            augmented.append(rewritten)

            # 添加噪音鲁棒性样本
            noisy = self.add_noise(sample)
            augmented.append(noisy)

        return augmented
```

#### 2.1.2 数据清洗核心流程

```python
import re
from typing import List, Dict

class DataCleaner:
    """数据清洗器"""

    def __init__(self):
        self.quality_checks = [
            self.check_length,
            self.check_format,
            self.check_language,
            self.check_duplicates,
            self.check_quality_score
        ]

    def clean(self, data: List[Dict]) -> List[Dict]:
        """清洗数据"""
        cleaned = []

        for sample in data:
            # 基础清洗
            sample = self.basic_clean(sample)

            # 质量检查
            if self.passes_quality_checks(sample):
                cleaned.append(sample)

        # 去重
        cleaned = self.deduplicate(cleaned)

        return cleaned

    def basic_clean(self, sample: Dict) -> Dict:
        """基础清洗"""
        for key in ['instruction', 'input', 'output']:
            if key in sample and sample[key]:
                text = sample[key]
                # 去除多余空白
                text = re.sub(r'\s+', ' ', text).strip()
                # 去除特殊字符
                text = re.sub(r'[\x00-\x1f\x7f-\x9f]', '', text)
                # 统一标点
                text = self.normalize_punctuation(text)
                sample[key] = text

        return sample

    def check_length(self, sample: Dict) -> bool:
        """检查长度"""
        instruction = sample.get('instruction', '')
        output = sample.get('output', '')

        # 指令不能太短
        if len(instruction) < 5:
            return False

        # 输出不能太短或太长
        if len(output) < 10 or len(output) > 10000:
            return False

        return True

    def check_format(self, sample: Dict) -> bool:
        """检查格式完整性"""
        required_fields = ['instruction', 'output']
        return all(sample.get(f) for f in required_fields)

    def check_quality_score(self, sample: Dict) -> bool:
        """使用LLM评估质量"""
        prompt = f"""请评估以下指令-回答对的质量（1-5分）：

指令：{sample['instruction']}
回答：{sample['output']}

评分标准：
5分：指令清晰，回答准确完整，格式规范
4分：整体良好，有小瑕疵
3分：可接受，但有明显问题
2分：质量较差，需要修改
1分：完全不可用

请只返回数字评分："""

        score = float(self.llm.generate(prompt).strip())
        return score >= 4

    def deduplicate(self, data: List[Dict]) -> List[Dict]:
        """去重"""
        seen = set()
        unique = []

        for sample in data:
            # 使用指令的hash作为去重key
            key = hash(sample['instruction'].lower().strip())
            if key not in seen:
                seen.add(key)
                unique.append(sample)

        return unique
```

#### 2.1.3 SFT vs RLHF数据差异

```
┌─────────────────────────────────────────────────────────────┐
│                 SFT vs RLHF 数据对比                        │
├─────────────────┬─────────────────┬─────────────────────────┤
│     维度        │      SFT        │        RLHF            │
├─────────────────┼─────────────────┼─────────────────────────┤
│  数据形式       │ 指令-回答对     │ 指令-多个回答-偏好排序   │
│  标注难度       │ 中等            │ 高                      │
│  标注成本       │ 相对较低        │ 较高                    │
│  训练目标       │ 模仿示例        │ 优化偏好                │
│  数据量要求     │ 数千-数万       │ 数万-数十万             │
├─────────────────┴─────────────────┴─────────────────────────┤
│                                                             │
│  SFT数据示例：                                               │
│  {                                                          │
│    "instruction": "解释什么是递归",                          │
│    "output": "递归是一种编程技术，函数调用自身..."            │
│  }                                                          │
│                                                             │
│  RLHF偏好数据示例：                                          │
│  {                                                          │
│    "instruction": "解释什么是递归",                          │
│    "chosen": "递归是函数调用自身的编程技术...",  // 更好     │
│    "rejected": "递归就是循环..."  // 较差                   │
│  }                                                          │
│                                                             │
└─────────────────────────────────────────────────────────────┘
```

### 2.2 微调结果评估

#### 2.2.1 自动化评估指标

```python
from nltk.translate.bleu_score import sentence_bleu
from rouge_score import rouge_scorer
import numpy as np

class AutoEvaluator:
    """自动评估器"""

    def __init__(self):
        self.rouge_scorer = rouge_scorer.RougeScorer(
            ['rouge1', 'rouge2', 'rougeL'],
            use_stemmer=True
        )

    def evaluate_bleu(self, predictions, references):
        """BLEU评分"""
        scores = []
        for pred, ref in zip(predictions, references):
            pred_tokens = pred.split()
            ref_tokens = [ref.split()]
            score = sentence_bleu(ref_tokens, pred_tokens)
            scores.append(score)
        return np.mean(scores)

    def evaluate_rouge(self, predictions, references):
        """ROUGE评分"""
        rouge1_scores = []
        rouge2_scores = []
        rougeL_scores = []

        for pred, ref in zip(predictions, references):
            scores = self.rouge_scorer.score(ref, pred)
            rouge1_scores.append(scores['rouge1'].fmeasure)
            rouge2_scores.append(scores['rouge2'].fmeasure)
            rougeL_scores.append(scores['rougeL'].fmeasure)

        return {
            'rouge1': np.mean(rouge1_scores),
            'rouge2': np.mean(rouge2_scores),
            'rougeL': np.mean(rougeL_scores)
        }

    def evaluate_exact_match(self, predictions, references):
        """精确匹配率"""
        matches = sum(
            1 for p, r in zip(predictions, references)
            if p.strip().lower() == r.strip().lower()
        )
        return matches / len(predictions)

    def evaluate_with_llm(self, predictions, references, instructions):
        """使用LLM评估"""
        scores = []
        for pred, ref, inst in zip(predictions, references, instructions):
            prompt = f"""请评估以下AI回答的质量（1-10分）：

指令：{inst}
参考答案：{ref}
模型回答：{pred}

评分标准：
- 准确性：回答是否正确
- 完整性：是否涵盖关键点
- 流畅性：语言是否通顺
- 相关性：是否切题

请给出评分（1-10）和简要理由："""

            response = self.llm.generate(prompt)
            score = self.parse_score(response)
            scores.append(score)

        return np.mean(scores)
```

#### 2.2.2 基准测试评估

```python
class BenchmarkEvaluator:
    """基准测试评估"""

    def __init__(self, model, tokenizer):
        self.model = model
        self.tokenizer = tokenizer

    def evaluate_mmlu(self, subset='all'):
        """MMLU评估（多任务语言理解）"""
        from datasets import load_dataset

        dataset = load_dataset("cais/mmlu", subset)
        correct = 0
        total = 0

        for sample in dataset['test']:
            question = sample['question']
            choices = sample['choices']
            answer = sample['answer']

            # 构建prompt
            prompt = f"""问题：{question}

选项：
A. {choices[0]}
B. {choices[1]}
C. {choices[2]}
D. {choices[3]}

请选择正确答案（A/B/C/D）："""

            # 生成回答
            response = self.generate(prompt)

            # 检查是否正确
            if self.parse_choice(response) == answer:
                correct += 1
            total += 1

        return correct / total

    def evaluate_ceval(self):
        """C-Eval评估（中文能力）"""
        from datasets import load_dataset

        dataset = load_dataset("ceval/ceval-exam")
        # 类似MMLU的评估流程
        pass

    def evaluate_gsm8k(self):
        """GSM8K评估（数学推理）"""
        from datasets import load_dataset

        dataset = load_dataset("gsm8k", "main")
        correct = 0
        total = 0

        for sample in dataset['test']:
            question = sample['question']
            answer = self.extract_number(sample['answer'])

            prompt = f"""请解决以下数学问题，给出详细步骤和最终答案。

问题：{question}

解答："""

            response = self.generate(prompt)
            predicted = self.extract_number(response)

            if predicted == answer:
                correct += 1
            total += 1

        return correct / total
```

---

## 第三章：LLM模型蒸馏与微调实操

### 3.1 LLM的模型蒸馏

#### 3.1.1 知识蒸馏的核心思想

```
┌─────────────────────────────────────────────────────────────┐
│                    知识蒸馏原理                             │
├─────────────────────────────────────────────────────────────┤
│                                                             │
│         教师模型（大模型）                                   │
│              ↓                                              │
│         软标签（概率分布）                                   │
│              ↓                                              │
│  ┌─────────────────────────────────────────────────────┐    │
│  │                 蒸馏损失                            │    │
│  │  L = α × L_hard + (1-α) × L_soft                   │    │
│  │                                                     │    │
│  │  L_hard: 学生模型与真实标签的交叉熵                  │    │
│  │  L_soft: 学生模型与教师软标签的KL散度               │    │
│  └─────────────────────────────────────────────────────┘    │
│              ↓                                              │
│         学生模型（小模型）                                   │
│                                                             │
│  蒸馏的价值：                                                │
│  ├── 模型压缩：小模型接近大模型效果                          │
│  ├── 推理加速：小模型推理更快                               │
│  ├── 知识迁移：教师知识转移到学生                            │
│  └── 部署优化：适合边缘设备                                  │
│                                                             │
└─────────────────────────────────────────────────────────────┘
```

#### 3.1.2 LLM时代的蒸馏挑战

```
LLM蒸馏的特殊挑战：

1. 规模差距大
   - 教师模型可能是70B+
   - 学生模型可能只有7B
   - 能力差距难以弥合

2. 任务复杂度高
   - 不是简单的分类任务
   - 需要保持生成质量

3. 输出空间巨大
   - 词表通常32K+
   - 软标签维度高

4. 解决方案：
   - 只蒸馏最重要的token
   - 使用teacher的输出作为SFT数据
   - 逐层蒸馏
   - 特定任务蒸馏
```

#### 3.1.3 蒸馏方法实现

```python
import torch
import torch.nn.functional as F

class DistillationTrainer:
    """LLM蒸馏训练器"""

    def __init__(self, teacher_model, student_model, tokenizer,
                 temperature=2.0, alpha=0.5):
        self.teacher = teacher_model
        self.student = student_model
        self.tokenizer = tokenizer
        self.temperature = temperature
        self.alpha = alpha

        # 冻结教师模型
        for param in self.teacher.parameters():
            param.requires_grad = False

    def compute_loss(self, inputs, labels):
        """计算蒸馏损失"""
        # 学生模型前向传播
        student_outputs = self.student(**inputs)
        student_logits = student_outputs.logits

        # 教师模型前向传播（不计算梯度）
        with torch.no_grad():
            teacher_outputs = self.teacher(**inputs)
            teacher_logits = teacher_outputs.logits

        # 硬标签损失
        hard_loss = F.cross_entropy(
            student_logits.view(-1, student_logits.size(-1)),
            labels.view(-1),
            ignore_index=-100
        )

        # 软标签损失（KL散度）
        soft_student = F.log_softmax(student_logits / self.temperature, dim=-1)
        soft_teacher = F.softmax(teacher_logits / self.temperature, dim=-1)

        soft_loss = F.kl_div(
            soft_student,
            soft_teacher,
            reduction='batchmean'
        ) * (self.temperature ** 2)

        # 组合损失
        total_loss = self.alpha * hard_loss + (1 - self.alpha) * soft_loss

        return total_loss, hard_loss, soft_loss

    def train_step(self, batch, optimizer):
        """训练步骤"""
        optimizer.zero_grad()

        inputs = {k: v.to(self.device) for k, v in batch.items() if k != 'labels'}
        labels = batch['labels'].to(self.device)

        total_loss, hard_loss, soft_loss = self.compute_loss(inputs, labels)

        total_loss.backward()
        optimizer.step()

        return {
            'total_loss': total_loss.item(),
            'hard_loss': hard_loss.item(),
            'soft_loss': soft_loss.item()
        }


# 简化版：使用教师输出作为SFT数据
class SimplifiedDistillation:
    """简化蒸馏：收集教师输出作为训练数据"""

    def __init__(self, teacher_model, student_model):
        self.teacher = teacher_model
        self.student = student_model

    def generate_training_data(self, prompts):
        """使用教师模型生成训练数据"""
        training_data = []

        for prompt in prompts:
            # 教师生成回答
            teacher_response = self.teacher.generate(prompt)

            training_data.append({
                'instruction': prompt,
                'output': teacher_response
            })

        return training_data

    def train_student(self, training_data):
        """使用生成的数据微调学生模型（标准SFT）"""
        # 使用标准的SFT流程训练学生模型
        pass
```

### 3.2 LLM模型微调实操

#### 3.2.1 使用Unsloth进行高效微调

```python
from unsloth import FastLanguageModel
import torch

# 加载模型（Unsloth优化版）
model, tokenizer = FastLanguageModel.from_pretrained(
    model_name="unsloth/Qwen2-7B",
    max_seq_length=2048,
    dtype=None,  # 自动检测
    load_in_4bit=True,  # 4bit量化
)

# 配置LoRA
model = FastLanguageModel.get_peft_model(
    model,
    r=16,  # LoRA秩
    target_modules=["q_proj", "k_proj", "v_proj", "o_proj",
                   "gate_proj", "up_proj", "down_proj"],
    lora_alpha=16,
    lora_dropout=0,
    bias="none",
    use_gradient_checkpointing="unsloth",  # 节省显存
    random_state=42,
)

# 准备数据
def formatting_func(examples):
    texts = []
    for instruction, output in zip(examples["instruction"], examples["output"]):
        text = f"""### 指令:
{instruction}

### 回答:
{output}"""
        texts.append(text)
    return {"text": texts}

from datasets import load_dataset
dataset = load_dataset("your_dataset")
dataset = dataset.map(formatting_func, batched=True)

# 训练配置
from trl import SFTTrainer
from transformers import TrainingArguments

trainer = SFTTrainer(
    model=model,
    tokenizer=tokenizer,
    train_dataset=dataset["train"],
    dataset_text_field="text",
    max_seq_length=2048,
    args=TrainingArguments(
        output_dir="./output",
        per_device_train_batch_size=2,
        gradient_accumulation_steps=4,
        warmup_steps=5,
        max_steps=100,
        learning_rate=2e-4,
        fp16=not torch.cuda.is_bf16_supported(),
        bf16=torch.cuda.is_bf16_supported(),
        logging_steps=1,
        optim="adamw_8bit",
        seed=42,
    ),
)

# 开始训练
trainer.train()

# 保存模型
model.save_pretrained("./lora_model")
tokenizer.save_pretrained("./lora_model")

# 合并权重（可选）
model.save_pretrained_merged("./merged_model", tokenizer)
```

---

## 第四章：视觉与多模态模型

### 4.1 多模态模型与视觉识别

#### 4.1.1 视觉识别的三大核心任务

```
┌─────────────────────────────────────────────────────────────┐
│                 CV三大核心任务                               │
├─────────────────────────────────────────────────────────────┤
│                                                             │
│  1. 图像分类 (Classification)                               │
│     ├── 任务：判断图像属于哪个类别                           │
│     ├── 输出：类别标签和置信度                               │
│     ├── 应用：商品识别、场景分类                             │
│     └── 模型：ResNet, ViT, EfficientNet                    │
│                                                             │
│  2. 目标检测 (Object Detection)                             │
│     ├── 任务：定位图像中的物体并分类                         │
│     ├── 输出：边界框(x,y,w,h) + 类别                        │
│     ├── 应用：自动驾驶、安防监控                             │
│     └── 模型：YOLO, Faster R-CNN, DETR                     │
│                                                             │
│  3. 图像分割 (Segmentation)                                 │
│     ├── 语义分割：像素级分类                                 │
│     ├── 实例分割：区分同类不同个体                           │
│     ├── 应用：医学影像、自动驾驶                             │
│     └── 模型：U-Net, Mask R-CNN, SAM                       │
│                                                             │
│  多模态VQA (Visual Question Answering)                      │
│     ├── 任务：根据图像回答问题                               │
│     ├── 输出：自然语言回答                                   │
│     ├── 应用：图像理解、视觉助手                             │
│     └── 模型：BLIP, LLaVA, Qwen-VL                         │
│                                                             │
└─────────────────────────────────────────────────────────────┘
```

#### 4.1.2 VLM在行业中的应用

```python
from transformers import Qwen2VLForConditionalGeneration, AutoProcessor
from PIL import Image

# 加载Qwen-VL模型
model = Qwen2VLForConditionalGeneration.from_pretrained(
    "Qwen/Qwen2-VL-7B-Instruct",
    torch_dtype="auto",
    device_map="auto"
)
processor = AutoProcessor.from_pretrained("Qwen/Qwen2-VL-7B-Instruct")

def analyze_image(image_path, question):
    """使用VLM分析图像"""
    image = Image.open(image_path)

    messages = [
        {
            "role": "user",
            "content": [
                {"type": "image", "image": image},
                {"type": "text", "text": question}
            ]
        }
    ]

    text = processor.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)
    inputs = processor(text=[text], images=[image], return_tensors="pt").to(model.device)

    generated_ids = model.generate(**inputs, max_new_tokens=512)
    response = processor.batch_decode(generated_ids, skip_special_tokens=True)[0]

    return response

# 应用示例
# 1. 商品识别
result = analyze_image("product.jpg", "这是什么商品？请描述其特征和可能的用途。")

# 2. 文档理解
result = analyze_image("document.jpg", "请提取这份文档中的关键信息。")

# 3. 质检应用
result = analyze_image("product_defect.jpg", "请检查这个产品是否有缺陷，如果有请指出缺陷位置和类型。")
```

### 4.2 训练YOLO目标检测模型

#### 4.2.1 数据集准备与标注

```python
"""
YOLO数据集目录结构：
dataset/
├── images/
│   ├── train/
│   │   ├── img001.jpg
│   │   └── ...
│   ├── val/
│   └── test/
├── labels/
│   ├── train/
│   │   ├── img001.txt  # 与图像同名
│   │   └── ...
│   ├── val/
│   └── test/
└── dataset.yaml

标签文件格式（每行一个目标）：
class_id x_center y_center width height
# 所有值都是归一化的（0-1）
"""

# dataset.yaml 配置
dataset_yaml = """
path: /path/to/dataset
train: images/train
val: images/val
test: images/test

nc: 3  # 类别数量
names:
  0: defect_scratch
  1: defect_crack
  2: defect_stain
"""

# 标签格式转换工具
def convert_voc_to_yolo(voc_annotation, image_size):
    """将VOC格式转换为YOLO格式"""
    img_w, img_h = image_size

    yolo_labels = []
    for obj in voc_annotation['objects']:
        class_id = obj['class_id']
        xmin, ymin, xmax, ymax = obj['bbox']

        # 转换为YOLO格式
        x_center = (xmin + xmax) / 2 / img_w
        y_center = (ymin + ymax) / 2 / img_h
        width = (xmax - xmin) / img_w
        height = (ymax - ymin) / img_h

        yolo_labels.append(f"{class_id} {x_center:.6f} {y_center:.6f} {width:.6f} {height:.6f}")

    return "\n".join(yolo_labels)
```

#### 4.2.2 训练自定义YOLO模型

```python
from ultralytics import YOLO

# 加载预训练模型
model = YOLO('yolov8n.pt')  # 或 yolov8s.pt, yolov8m.pt 等

# 训练配置
results = model.train(
    data='dataset.yaml',
    epochs=100,
    imgsz=640,
    batch=16,
    device=0,

    # 数据增强
    augment=True,
    hsv_h=0.015,
    hsv_s=0.7,
    hsv_v=0.4,
    degrees=0.0,
    translate=0.1,
    scale=0.5,
    shear=0.0,
    perspective=0.0,
    flipud=0.0,
    fliplr=0.5,
    mosaic=1.0,
    mixup=0.0,

    # 训练策略
    optimizer='AdamW',
    lr0=0.01,
    lrf=0.01,
    momentum=0.937,
    weight_decay=0.0005,
    warmup_epochs=3.0,
    warmup_momentum=0.8,
    warmup_bias_lr=0.1,

    # 早停
    patience=50,

    # 保存
    project='runs/detect',
    name='defect_detection',
    save=True,
    save_period=10,
)

# 验证
metrics = model.val()
print(f"mAP50: {metrics.box.map50:.4f}")
print(f"mAP50-95: {metrics.box.map:.4f}")

# 测试推理
results = model('test_image.jpg')
for result in results:
    print(f"检测到 {len(result.boxes)} 个目标")
    for box in result.boxes:
        print(f"  类别: {result.names[int(box.cls)]}, 置信度: {box.conf:.2f}")
```

#### 4.2.3 模型评估指标

```python
"""
目标检测评估指标：

1. Precision（精确率）
   P = TP / (TP + FP)
   真正例 / 所有预测为正的样本

2. Recall（召回率）
   R = TP / (TP + FN)
   真正例 / 所有实际为正的样本

3. AP（Average Precision）
   PR曲线下面积，综合考虑精确率和召回率

4. mAP（mean Average Precision）
   所有类别AP的平均值

5. mAP50
   IoU阈值为0.5时的mAP

6. mAP50-95
   IoU阈值从0.5到0.95的mAP平均值

7. IoU（Intersection over Union）
   交并比，衡量预测框与真实框的重叠程度
"""

def calculate_iou(box1, box2):
    """计算IoU"""
    x1_inter = max(box1[0], box2[0])
    y1_inter = max(box1[1], box2[1])
    x2_inter = min(box1[2], box2[2])
    y2_inter = min(box1[3], box2[3])

    inter_area = max(0, x2_inter - x1_inter) * max(0, y2_inter - y1_inter)

    box1_area = (box1[2] - box1[0]) * (box1[3] - box1[1])
    box2_area = (box2[2] - box2[0]) * (box2[3] - box2[1])

    union_area = box1_area + box2_area - inter_area

    return inter_area / union_area if union_area > 0 else 0
```

---

## 第五章：项目实战——AI质检

### 5.1 技术选型：YOLO vs Qwen-VL

```
┌─────────────────────────────────────────────────────────────┐
│              YOLO vs Qwen-VL 对比                           │
├─────────────────┬─────────────────┬─────────────────────────┤
│     维度        │      YOLO       │       Qwen-VL          │
├─────────────────┼─────────────────┼─────────────────────────┤
│  任务类型       │ 目标检测        │ 视觉理解/VQA           │
│  输出形式       │ 边界框+类别     │ 自然语言描述           │
│  推理速度       │ 快（毫秒级）    │ 慢（秒级）             │
│  训练数据       │ 需要标注边界框   │ 可零样本/少样本        │
│  定制难度       │ 需要大量标注    │ 提示词调整即可         │
│  精度           │ 高（针对性训练） │ 中等（通用能力）       │
│  部署成本       │ 低              │ 高（需要大显存）       │
│  适用场景       │ 固定类别检测    │ 开放式缺陷描述         │
├─────────────────┴─────────────────┴─────────────────────────┤
│                                                             │
│  最佳实践：                                                  │
│  ├── 明确缺陷类型、追求高速 → YOLO                          │
│  ├── 需要详细缺陷描述、灵活判断 → Qwen-VL                    │
│  └── 组合使用：YOLO检测 + VLM描述分析                       │
│                                                             │
└─────────────────────────────────────────────────────────────┘
```

### 5.2 完整项目实现

```python
from ultralytics import YOLO
from transformers import Qwen2VLForConditionalGeneration, AutoProcessor
from PIL import Image
import cv2
import numpy as np

class AIQualityInspector:
    """AI质检系统"""

    def __init__(self, yolo_model_path, use_vlm=True):
        # 加载YOLO模型
        self.yolo = YOLO(yolo_model_path)

        # 可选：加载VLM进行详细分析
        self.use_vlm = use_vlm
        if use_vlm:
            self.vlm = Qwen2VLForConditionalGeneration.from_pretrained(
                "Qwen/Qwen2-VL-7B-Instruct",
                torch_dtype="auto",
                device_map="auto"
            )
            self.vlm_processor = AutoProcessor.from_pretrained("Qwen/Qwen2-VL-7B-Instruct")

        # 缺陷严重程度映射
        self.severity_map = {
            'scratch': 'medium',
            'crack': 'high',
            'stain': 'low',
            'dent': 'high'
        }

    def detect_defects(self, image_path, conf_threshold=0.5):
        """使用YOLO检测缺陷"""
        results = self.yolo(image_path, conf=conf_threshold)

        defects = []
        for result in results:
            for box in result.boxes:
                defect = {
                    'class': result.names[int(box.cls)],
                    'confidence': float(box.conf),
                    'bbox': box.xyxy[0].tolist(),
                    'severity': self.severity_map.get(result.names[int(box.cls)], 'unknown')
                }
                defects.append(defect)

        return defects, results[0].plot()

    def analyze_with_vlm(self, image_path, defects):
        """使用VLM进行详细分析"""
        if not self.use_vlm:
            return None

        image = Image.open(image_path)

        # 构建分析提示
        defect_summary = "\n".join([
            f"- {d['class']} (置信度: {d['confidence']:.2f})"
            for d in defects
        ])

        prompt = f"""这是一张产品质检图片，系统已检测到以下缺陷：
{defect_summary}

请详细分析：
1. 每个缺陷的具体特征
2. 可能的产生原因
3. 对产品质量的影响程度
4. 建议的处理方式（返工/降级/报废）"""

        messages = [
            {
                "role": "user",
                "content": [
                    {"type": "image", "image": image},
                    {"type": "text", "text": prompt}
                ]
            }
        ]

        text = self.vlm_processor.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)
        inputs = self.vlm_processor(text=[text], images=[image], return_tensors="pt").to(self.vlm.device)

        generated_ids = self.vlm.generate(**inputs, max_new_tokens=512)
        response = self.vlm_processor.batch_decode(generated_ids, skip_special_tokens=True)[0]

        return response

    def inspect(self, image_path):
        """完整质检流程"""
        # 1. 检测缺陷
        defects, annotated_image = self.detect_defects(image_path)

        # 2. 判定结果
        if len(defects) == 0:
            verdict = "PASS"
            recommendation = "产品合格，可以出货"
        else:
            # 检查是否有严重缺陷
            high_severity = any(d['severity'] == 'high' for d in defects)
            if high_severity:
                verdict = "FAIL"
                recommendation = "存在严重缺陷，建议报废或返工"
            else:
                verdict = "WARNING"
                recommendation = "存在轻微缺陷，可降级处理"

        # 3. VLM详细分析（可选）
        vlm_analysis = None
        if defects and self.use_vlm:
            vlm_analysis = self.analyze_with_vlm(image_path, defects)

        return {
            'verdict': verdict,
            'defects': defects,
            'defect_count': len(defects),
            'recommendation': recommendation,
            'vlm_analysis': vlm_analysis,
            'annotated_image': annotated_image
        }


# 使用示例
inspector = AIQualityInspector(
    yolo_model_path='runs/detect/defect_detection/weights/best.pt',
    use_vlm=True
)

result = inspector.inspect('product_image.jpg')

print(f"判定结果: {result['verdict']}")
print(f"缺陷数量: {result['defect_count']}")
print(f"建议: {result['recommendation']}")

if result['vlm_analysis']:
    print(f"\n详细分析:\n{result['vlm_analysis']}")

# 保存标注图像
cv2.imwrite('result.jpg', result['annotated_image'])
```

---

## 专项求职辅导

### 模型训练与微调面试问题

**1. 请详细讲讲LoRA的原理**

```
LoRA核心原理：

1. 低秩假设
   - 微调时权重变化ΔW是低秩的
   - 可以用两个小矩阵相乘近似

2. 数学表达
   - ΔW = B × A
   - B: (d, r), A: (r, k), r << d, k
   - 参数量从 d×k 降到 r×(d+k)

3. 初始化
   - A: 随机初始化（高斯分布）
   - B: 零初始化
   - 确保开始时ΔW=0

4. 训练时
   - 冻结原始权重W
   - 只训练A和B

5. 推理时
   - 可以合并：W' = W + BA
   - 无额外推理开销
```

**2. 你认为一条'高质量'的微调数据应该符合什么标准？**

```
高质量数据标准：

1. 格式规范
   - 指令清晰明确
   - 输出完整规范
   - 无格式错误

2. 内容准确
   - 回答正确无误
   - 专业术语准确
   - 无事实错误

3. 指令多样
   - 表述方式多样
   - 覆盖各种场景
   - 难度分布合理

4. 长度适中
   - 不过短（<10字）
   - 不过长（>2000字）
   - 与任务匹配

5. 安全合规
   - 无有害内容
   - 无隐私信息
   - 符合伦理规范
```

**3. 你如何评估微调后的模型效果？**

```
评估体系：

1. 自动指标
   - 困惑度(Perplexity)
   - BLEU/ROUGE
   - 精确匹配率

2. 基准测试
   - MMLU（通用能力）
   - C-Eval（中文）
   - GSM8K（数学）
   - HumanEval（代码）

3. 业务指标
   - 任务完成率
   - 用户满意度
   - 响应准确率

4. 人工评估
   - 专家打分
   - A/B测试
   - 盲评对比
```

---

## 本模块总结

### 核心能力清单

1. **LoRA原理**：理解低秩分解的数学原理
2. **数据工程**：掌握微调数据的收集、清洗、标准
3. **显存估算**：能估算不同配置的显存需求
4. **知识蒸馏**：理解蒸馏原理和LLM蒸馏方法
5. **微调实操**：会用Unsloth等工具进行LoRA微调
6. **YOLO训练**：能训练自定义目标检测模型
7. **VLM应用**：能使用多模态模型进行视觉分析

### 实践建议

1. 数据质量优先于数量
2. 从小规模数据开始验证
3. 建立完善的评估体系
4. 注意显存优化技巧
